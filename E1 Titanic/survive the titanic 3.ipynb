{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Application of SVM using tensorflow, seperated aout this procedure to reduce clutter\n",
    "#For brevity, we use linear seperator kernels, obvious from the 3d plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "\n",
    "ops.reset_default_graph()\n",
    "\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.read_csv(\"train.csv\")\n",
    "data_file = data_file.drop(['Ticket','Cabin','PassengerId','Name'], axis=1)\n",
    "data_file = data_file.dropna()\n",
    "\n",
    "def to_numeric_str(var):\n",
    "    if var=='male':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "data_file['Sex_num'] = 0\n",
    "data_file[['Sex_num']] = data_file[['Sex']].apply(lambda row: to_numeric_str(row['Sex']),axis=1)\n",
    "data_file = data_file.drop(['Sex'],axis=1)\n",
    "data_file[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_file.as_matrix()\n",
    "x_data = np.array([[x[1],x[2],x[3],x[4],x[5],x[7]] for x in data])\n",
    "#Converting into classes 1 and -1\n",
    "y_data = np.array([1 if x[0]==1 else -1 for x in data])\n",
    "\n",
    "#Splitting data into train/test 90 and 10 percent\n",
    "train_idx = np.random.choice(len(x_data), int(round(len(x_data)*0.9)), replace=False)\n",
    "test_idx = np.array(list(set(range(len(x_data))) - set(train_idx)))\n",
    "x_train = x_data[train_idx]\n",
    "y_train = y_data[train_idx]\n",
    "\n",
    "x_test = x_data[test_idx]\n",
    "y_test = y_data[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "graph_ = tf.Graph()\n",
    "with graph_.as_default():\n",
    "    #Creation of tensorflow graph\n",
    "    with tf.device('/cpu:0'):\n",
    "        x_feed = tf.placeholder(shape = [None, 6], dtype = tf.float32)\n",
    "        y_feed = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
    "\n",
    "        #Declaration of seperator, for margin maximization\n",
    "        A = tf.Variable(tf.random_normal(shape=[6,1]))\n",
    "        b = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "\n",
    "        #Eqation of line, y = Ax-b\n",
    "        out = tf.subtract(tf.matmul(x_feed,A),b)\n",
    "\n",
    "        #Maximize the norm(W)^2, here it is just W = A\n",
    "        l2_norm = tf.reduce_sum(tf.square(A))\n",
    "\n",
    "        #Additionaly, for regularization, we add some more paramters\n",
    "        #regularization_term = max(0, 1-pred*actual)\n",
    "        alpha = tf.constant([0.001])\n",
    "        regularization_term = tf.reduce_mean(tf.maximum(0., tf.subtract(1., tf.multiply(out,y_feed))))\n",
    "\n",
    "        #Loss function\n",
    "        loss = tf.add(regularization_term, tf.multiply(alpha, l2_norm))\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "        #Defining varibales of interest\n",
    "        train_model = optimizer.minimize(loss)\n",
    "\n",
    "        #We are interested in sign, depicting two classes\n",
    "        prediction = tf.sign(out)\n",
    "        nr_correct = tf.cast(tf.equal(prediction, y_feed), tf.float32)\n",
    "        accuracy = tf.reduce_mean(nr_correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.Session(graph=graph_,config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for i in range(100000):\n",
    "        random_batch_choice = np.random.choice(len(x_train), size = batch_size)\n",
    "        random_x = x_train[random_batch_choice]\n",
    "        random_y = np.transpose([y_train[random_batch_choice]])\n",
    "        sess.run(train_model, feed_dict={x_feed:random_x, y_feed:random_y})\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={x_feed:x_test, y_feed:np.transpose([y_test])})\n",
    "        if(i%5000==0):\n",
    "            print(\"Test accuracy at step \", i, \" is \",test_accuracy)\n",
    "    #Get the answer for real data\n",
    "    #ans = sess.run(prediction, feed_dict={x_feed:x_data_ans})\n",
    "    #ans[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next to try: Non-linear SVM kernel\n",
    "#Next to next: Decision trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
